# LSTM (Long Short-Term Memory)

## Назначение
Рекуррентная нейросеть с ячейками памяти для моделирования временных зависимостей. Подходит для прогнозирования направленных сигналов long/short на основе последовательных данных цен и индикаторов.

## Ключевые особенности
- Улавливает долгосрочные и краткосрочные зависимости во временных рядах.
- Гибкая архитектура: однонаправленные, двунаправленные, многослойные конфигурации.
- Реализуется на PyTorch с поддержкой GPU-ускорения.

## Типичные гиперпараметры
- `hidden_size`: размер скрытого состояния.
- `num_layers`: количество слоёв LSTM.
- `dropout`: регуляризация между слоями.
- `bidirectional`: использование двунаправленных связей.
- `batch_size`, `sequence_length`, `learning_rate`, `optimizer`.

## Требования к данным
- Формирование последовательностей фиксированной длины (rolling window).
- Нормализация признаков в каждом окне увеличивает стабильность обучения.
- Разметка: поддержка long-only, short-only, long+short через соответствующие таргеты.

## Метрики и валидация
- Accuracy, F1, ROC-AUC, трейдинговые метрики.
- Валидация по временным сплитам (walk-forward, expanding window).
- Мониторинг валидационного лосса, ранняя остановка и чекпоинтинг.

## Интеграция в конвейер
- Реализовать интерфейс `fit/predict/predict_proba` (через обёртку PyTorch Lightning или кастомный тренер).
- Хранить веса модели, параметры нормализации и конфигурации окон.
- Логировать hidden-state анализ, если требуется интерпретация.

## Ограничения и рекомендации
- Подвержена градиентному затуханию на длинных последовательностях (использовать gradient clipping).
- Более ресурсоёмкая по сравнению с бустингом; требует GPU.
- Рекомендуется начинать с базовых длины окон и размера скрытого состояния, затем тюнинговать.
