# SAM (Sharpness-Aware Minimization)

## Назначение
Техника оптимизации, нацеленная на поиск плоских минимумов. Добавляется поверх базового оптимизатора (SGD/Adam) и повышает обобщающую способность.

## Принцип
- На каждом шаге выполняются два прохода: шаг в направлении градиента и обновление в худшей точке в окрестности радиуса ρ.
- Использует `rho` (радиус) и базовый оптимизатор.

## Рекомендации
- Применять совместно с AdamW/SGD.
- Использовать небольшой `rho` (0.05–0.2).
- Требует увеличения времени обучения (двойной проход), планировать ресурсы.
