# Binary Cross-Entropy / BCEWithLogitsLoss

## Назначение
Базовая функция потерь для бинарной классификации (например, long против not-long) и многолейбловых задач. Вариант `BCEWithLogitsLoss` в PyTorch объединяет сигмоиду и BCE для численной стабильности.

## Формула
\( \text{BCE}(y, \hat{y}) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log \hat{y}_i + (1 - y_i) \log (1 - \hat{y}_i)] \)

## Особенности
- Простота и широкая поддержка во фреймворках.
- Поддерживает веса классов (`pos_weight`, `weight`) для компенсации дисбаланса long/short.
- Требует вероятностных выходов модели (0–1).

## Рекомендации
- Для `long-only` или `short-only` сценариев формируйте бинарные таргеты (сигнал vs отсутствие сигнала).
- Контролируйте стабильность тренировок при крайне несбалансированных классах (добавляйте веса или Focal Loss).
