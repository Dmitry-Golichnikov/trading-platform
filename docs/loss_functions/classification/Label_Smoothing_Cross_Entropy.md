# Label Smoothing Cross-Entropy

## Назначение
Смягчает целевые метки, уменьшая перенастройку модели на «жёсткие» one-hot цели. Помогает повысить устойчивость и качество калибровки вероятностей.

## Формула
Вводится параметр smoothing \(\epsilon\). Для правильного класса вероятность \(1 - \epsilon\), для остальных распределяется \(\epsilon/(C-1)\).

## Особенности
- Снижает переобучение на шумных данных.
- Улучшает calibrated probabilities, что важно для последующей оценки Precision/Recall.
- Не подходит, если требуется строгое соответствие one-hot (например, жёсткая интерпретация ошибочных классов).

## Рекомендации
- Выбирать \(\epsilon\) в диапазоне 0.05–0.2.
- Использовать с CrossEntropyLoss, включая PyTorch-реализацию (`label_smoothing` аргумент) и при необходимости комбинировать с `class_weight`.
