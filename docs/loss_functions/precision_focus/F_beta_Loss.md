# F-beta Loss

## Назначение
Расширение F1-loss с акцентом на Precision (\(\beta < 1\)) или Recall (\(\beta > 1\)). Полезно в торговых моделях, где ложные сигналы дорого обходятся.

## Формула (пример)
\( F_\beta = \frac{(1+\beta^2) \cdot TP}{(1+\beta^2) \cdot TP + \beta^2 \cdot FN + FP} \), loss = 1 − F_\beta, с непрерывными TP/FN/FP через предсказанные вероятности.

## Особенности
- При \(\beta < 1\) увеличивает важность Precision.
- Требует сглаживания/аппроксимации для градиентного расчёта.
- Можно реализовать как дифференцируемую функцию (soft counts) и при необходимости вводить веса классов.

## Рекомендации
- Выбирать \(\beta\) исходя из стоимости ложных сигналов (например, 0.5 для приоритета Precision).
- Использовать вместе с BCE или регуляризаторами для устойчивости градиентов.
