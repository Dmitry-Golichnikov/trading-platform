# Этап 06: Базовая инфраструктура моделирования

## Цель
Создать единый интерфейс для всех моделей, систему регистрации и базовые утилиты обучения.

## Зависимости
Этапы 00-05

## Структура

```
src/modeling/
├── base.py                       # BaseModel интерфейс
├── registry.py                   # ModelRegistry
├── trainer.py                    # ModelTrainer
├── models/                       # Реализации моделей
│   ├── __init__.py
│   ├── linear/
│   ├── tree_based/
│   └── neural/
├── loss_functions/               # Loss functions
├── optimizers/                   # Optimizers
├── callbacks/                    # Training callbacks
└── utils.py                      # Утилиты
```

## Основные компоненты

### 1. BaseModel интерфейс
```python
class BaseModel(ABC):
    """Единый интерфейс для всех моделей"""

    @abstractmethod
    def fit(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> "BaseModel":
        """Обучить модель"""
        pass

    @abstractmethod
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """Предсказания (labels для классификации)"""
        pass

    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """Вероятности классов (для классификаторов)"""
        raise NotImplementedError("Model doesn't support probabilities")

    @abstractmethod
    def save(self, path: Path) -> None:
        """Сохранить модель"""
        pass

    @classmethod
    @abstractmethod
    def load(cls, path: Path) -> "BaseModel":
        """Загрузить модель"""
        pass

    @property
    @abstractmethod
    def feature_importances_(self) -> Optional[np.ndarray]:
        """Feature importances (если поддерживается)"""
        pass
```

### 2. ModelRegistry
```python
class ModelRegistry:
    """Реестр моделей"""

    _models: dict[str, Type[BaseModel]] = {}

    @classmethod
    def register(cls, name: str):
        """Декоратор для регистрации"""
        def decorator(model_class):
            cls._models[name] = model_class
            return model_class
        return decorator

    @classmethod
    def create(cls, name: str, **kwargs) -> BaseModel:
        """Создать экземпляр модели"""
        if name not in cls._models:
            raise ValueError(f"Unknown model: {name}")
        return cls._models[name](**kwargs)
```

### 3. ModelTrainer
```python
class ModelTrainer:
    """Обучение моделей с tracking"""

    def __init__(
        self,
        model: BaseModel,
        experiment_name: str,
        mlflow_uri: str = None
    ):
        self.model = model
        self.experiment_name = experiment_name
        self.mlflow_client = MLflowClient(mlflow_uri)

    def train(
        self,
        X_train, y_train,
        X_val, y_val,
        callbacks: list[Callback] = None
    ) -> TrainingResult:
        """
        Обучить с tracking в MLflow

        Returns:
            TrainingResult с метриками, путями к артефактам
        """
```

### 4. Training Callbacks
```python
class Callback(ABC):
    """Базовый callback"""

    def on_train_begin(self, trainer): pass
    def on_epoch_begin(self, epoch): pass
    def on_epoch_end(self, epoch, logs): pass
    def on_train_end(self, logs): pass

class EarlyStopping(Callback):
    """Ранняя остановка"""

class ModelCheckpoint(Callback):
    """Сохранение лучшей модели"""

class MLflowLogger(Callback):
    """Логирование в MLflow"""

class ProgressBar(Callback):
    """Progress bar для обучения"""
```

### 5. Loss Functions

**src/modeling/loss_functions/registry.py:**
```python
class LossRegistry:
    """Реестр loss functions"""

    _losses = {
        # Classification
        'bce': BinaryCrossEntropy(),
        'focal': FocalLoss(),
        'weighted_bce': WeightedBCE(),

        # Regression
        'mse': MSELoss(),
        'mae': MAELoss(),
        'huber': HuberLoss(),
        'quantile': QuantileLoss(),

        # Custom
        'directional_loss': DirectionalLoss(),
        'profit_based_loss': ProfitBasedLoss(),
    }
```

**Категории (согласно docs/loss_functions/):**
- Classification: BCE, Focal, Label Smoothing
- Regression: MSE, MAE, Huber, Quantile
- Weighted: Weighted BCE, Cost-sensitive
- Ranking: Pairwise, Listwise
- Trading custom: Profit-based, Sharpe-based

### 6. Data splitting
```python
class DataSplitter:
    """Разделение данных train/val/test"""

    @staticmethod
    def split_sequential(
        data: pd.DataFrame,
        train_size: float = 0.7,
        val_size: float = 0.15,
        test_size: float = 0.15
    ) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """Последовательное разделение (для временных рядов)"""

    @staticmethod
    def split_walk_forward(
        data: pd.DataFrame,
        n_splits: int = 5,
        test_size: int = None
    ) -> list[tuple[pd.DataFrame, pd.DataFrame]]:
        """Walk-forward splitting"""

    @staticmethod
    def split_purged(
        data: pd.DataFrame,
        train_size: float = 0.7,
        embargo_td: timedelta = timedelta(days=1)
    ) -> tuple:
        """Purged split (для избежания leakage)"""
```

### 7. Model serialization
```python
class ModelSerializer:
    """Сериализация моделей"""

    @staticmethod
    def save(model: BaseModel, path: Path, format: str = 'pickle'):
        """
        Сохранить модель

        Formats: 'pickle', 'joblib', 'onnx', 'torchscript'
        """

    @staticmethod
    def load(path: Path, format: str = None) -> BaseModel:
        """Загрузить модель (автоопределение формата)"""
```

### 8. Sanity checks
```python
class ModelSanityChecker:
    """Проверки перед обучением"""

    def check_target_distribution(self, y: pd.Series):
        """Проверить распределение таргета"""
        # Дисбаланс классов
        # Слишком мало примеров
        # Constant target

    def check_look_ahead(self, X: pd.DataFrame, y: pd.Series):
        """Проверить look-ahead bias"""
        # Target не должен содержать будущую инфо

    def check_data_leakage(self, X_train, X_val, y_train, y_val):
        """Проверить утечку данных"""
        # Дубликаты между train и val
        # Временной overlap

    def check_feature_quality(self, X: pd.DataFrame):
        """Проверить качество признаков"""
        # Слишком много NaN
        # Constant features
        # Высокая корреляция
```

## Критерии готовности

- [ ] BaseModel интерфейс определён
- [ ] ModelRegistry работает
- [ ] ModelTrainer работает
- [ ] Callbacks реализованы (EarlyStopping, Checkpoint, MLflow)
- [ ] Loss functions registry
- [ ] Data splitting методы
- [ ] Model serialization (pickle, ONNX)
- [ ] Sanity checks перед обучением
- [ ] Интеграция с MLflow
- [ ] Документация API

## Промпты для реализации

### Промпт 1: Базовые интерфейсы
```
Реализуй базовую инфраструктуру в src/modeling/:

1. base.py - BaseModel абстрактный класс с полным интерфейсом
2. registry.py - ModelRegistry для регистрации моделей
3. utils.py - утилиты (set_seed, reproducibility, device management)

BaseModel должен поддерживать:
- fit/predict/predict_proba
- save/load
- feature_importances_
- Метаданные модели (hyperparams, training_time, etc)

Используй Protocol для type hints.
```

### Промпт 2: ModelTrainer и Callbacks
```
Реализуй:
1. trainer.py - ModelTrainer с MLflow integration
2. callbacks.py - все callbacks

ModelTrainer должен:
- Логировать метрики в MLflow
- Сохранять артефакты (модель, графики, config)
- Поддерживать callbacks
- Вычислять и логировать training time
- Обрабатывать ошибки gracefully

Callbacks: EarlyStopping, ModelCheckpoint, MLflowLogger, ProgressBar
```

### Промпт 3: Loss Functions
```
Создай систему loss functions в src/modeling/loss_functions/:

1. base.py - BaseLoss интерфейс
2. registry.py - LossRegistry
3. classification/ - BCE, Focal, Weighted
4. regression/ - MSE, MAE, Huber, Quantile
5. trading_custom/ - DirectionalLoss, ProfitBasedLoss

Каждая loss должна:
- Наследоваться от BaseLoss
- Поддерживать PyTorch и sklearn API
- Иметь docstring с формулой
- Быть зарегистрирована

Используй спецификации из docs/loss_functions/.
```

### Промпт 4: Data Splitting и Serialization
```
Реализуй:
1. splitting.py - DataSplitter с методами:
   - split_sequential
   - split_walk_forward
   - split_purged (with embargo)

2. serialization.py - ModelSerializer:
   - save/load для pickle, joblib
   - Экспорт в ONNX (для нейросетей)
   - Сохранение метаданных вместе с моделью

3. sanity_checks.py - ModelSanityChecker:
   - Все проверки из спецификации
   - Генерация отчёта о проблемах
```

### Промпт 5: Интеграция и тесты
```
1. Интеграция с MLflow:
   - Автоматическое создание experiments
   - Логирование hyperparams, metrics, artifacts
   - Тэги для моделей

2. Тесты:
   - tests/unit/modeling/test_base.py
   - tests/unit/modeling/test_registry.py
   - tests/unit/modeling/test_trainer.py
   - tests/unit/modeling/test_callbacks.py
   - tests/unit/modeling/test_loss_functions.py

Используй mock для MLflow в тестах.
```

## Важные замечания

**Единообразие API:**
Все модели должны иметь одинаковый интерфейс независимо от библиотеки (sklearn, PyTorch, etc).

**MLflow tracking:**
- Автоматически логировать всё важное
- Структурированные тэги для поиска
- Сохранять config вместе с моделью

**Reproducibility:**
- Фиксация seeds
- Сохранение точной версии библиотек
- Детерминистические операции где возможно

**GPU support:**
- Автоопределение доступности GPU
- Graceful fallback на CPU
- Управление памятью GPU

**Sanity checks:**
Критично! Они спасут много времени на debugging.

## Следующий этап
[Этап 07: Классические ML модели](Этап_07_Классические_ML_модели.md)
