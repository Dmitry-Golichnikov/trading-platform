# Этап 09: Система обучения и оптимизации гиперпараметров

## Цель
Реализовать систему поиска гиперпараметров, автоматического обучения и tracking экспериментов.

## Зависимости
Этапы 06-08

## Компоненты

### 1. Hyperparameter Search
```
src/modeling/hyperopt/
├── base.py                       # BaseOptimizer
├── grid_search.py
├── random_search.py
├── bayesian.py                   # Bayesian Optimization
├── optuna_backend.py             # Optuna integration
├── genetic.py                    # Genetic algorithms
└── hyperband.py                  # Hyperband/BOHB
```

### 2. Search spaces
```yaml
# configs/hyperopt/lightgbm_search_space.yaml
search_space:
  num_leaves:
    type: int
    low: 20
    high: 150

  learning_rate:
    type: float
    low: 0.001
    high: 0.3
    log: true

  feature_fraction:
    type: float
    low: 0.5
    high: 1.0

  max_depth:
    type: categorical
    choices: [-1, 5, 10, 20]

search_config:
  method: bayesian  # grid, random, bayesian, optuna
  n_trials: 100
  timeout: 3600  # seconds
  metric: roc_auc
  direction: maximize

  pruning:
    enabled: true
    warmup_steps: 10
```

### 3. Multi-level optimization
```python
class MultiLevelOptimizer:
    """
    Многоуровневая оптимизация с "заморозкой" блоков

    Уровни:
    1. Data preparation (filters, samplers)
    2. Features (feature selection)
    3. Model architecture
    4. Model hyperparameters
    5. Training params (LR, optimizer)
    6. Strategy params (thresholds, TP/SL)
    """

    def optimize_hierarchical(self, config: dict):
        """Последовательная оптимизация уровней"""

        # Level 1: Data
        best_data_config = self.optimize_data_prep()

        # Level 2: Features (зафиксирован data config)
        best_features = self.optimize_features(best_data_config)

        # Level 3: Model (зафиксированы data + features)
        best_model = self.optimize_model(best_data_config, best_features)

        # и т.д.
```

### 4. Threshold optimization
```python
class ThresholdOptimizer:
    """
    Оптимизация порога по ожидаемому PnL

    E[PnL] = p_up * TP - (1 - p_up) * SL - комиссии
    """

    def optimize_threshold(
        self,
        y_proba: np.ndarray,
        y_true: np.ndarray,
        tp: float,
        sl: float,
        commission: float = 0.001,
        constraints: dict = None
    ) -> dict:
        """
        Найти оптимальный threshold

        Constraints:
        - min_trades: минимум сделок
        - max_drawdown: максимальная просадка
        - min_sharpe: минимальный Sharpe
        """
```

### 5. Auto-ML pipeline
```python
class AutoMLPipeline:
    """Автоматический поиск лучшей конфигурации"""

    def fit(
        self,
        X_train, y_train,
        X_val, y_val,
        search_space: dict,
        time_budget: int = 3600
    ):
        """
        Автоматический поиск:
        1. Feature selection
        2. Model selection
        3. Hyperparameter tuning
        4. Ensemble construction
        """
```

### 6. Warm start from meta-learning
```python
class MetaLearning:
    """Meta-learning layer для warm-start"""

    def __init__(self, history_db: Path):
        self.history = self._load_history(history_db)

    def suggest_starting_point(
        self,
        dataset_meta: dict,
        model_type: str
    ) -> dict:
        """
        Предложить стартовую точку на основе
        похожих предыдущих экспериментов
        """
        similar = self._find_similar_datasets(dataset_meta)
        best_configs = self._get_best_configs(similar, model_type)
        return self._aggregate_configs(best_configs)
```

### 7. Experiment tracking
```python
class ExperimentTracker:
    """Централизованный tracking экспериментов"""

    def log_experiment(
        self,
        config: dict,
        metrics: dict,
        artifacts: dict,
        tags: dict
    ):
        """Логирование в MLflow + локальная БД"""

    def compare_experiments(
        self,
        experiment_ids: list[str],
        metrics: list[str] = None
    ) -> pd.DataFrame:
        """Сравнение экспериментов"""

    def get_best_experiment(
        self,
        metric: str,
        filters: dict = None
    ) -> dict:
        """Найти лучший эксперимент"""
```

## Критерии готовности

- [ ] Grid/Random/Bayesian search работают
- [ ] Optuna integration
- [ ] Multi-level optimization реализована
- [ ] Threshold optimizer работает
- [ ] AutoML pipeline базовый
- [ ] Meta-learning warm-start
- [ ] Pruning неэффективных trials
- [ ] Parallel trials (если возможно)
- [ ] Experiment tracking в MLflow
- [ ] CLI: `hyperopt`, `automl`, `compare-experiments`

## Промпты

### Промпт 1: Базовые search методы
```
Реализуй в src/modeling/hyperopt/:

1. base.py - BaseOptimizer абстрактный класс
2. grid_search.py - Grid search
3. random_search.py - Random search
4. bayesian.py - Bayesian optimization (используй scikit-optimize)
5. optuna_backend.py - Optuna integration

Каждый optimizer:
- Принимает search space (YAML config)
- Оптимизирует заданную метрику
- Поддерживает callbacks
- Логирует все trials в MLflow
- Поддерживает pruning
```

### Промпт 2: Multi-level и threshold optimization
```
Реализуй:
1. multi_level_optimizer.py - MultiLevelOptimizer
2. threshold_optimizer.py - ThresholdOptimizer с формулой E[PnL]

MultiLevelOptimizer должен:
- Оптимизировать уровни последовательно
- "Замораживать" предыдущие уровни
- Сохранять лучшие конфиги каждого уровня

ThresholdOptimizer:
- Вычислять ожидаемый PnL для каждого threshold
- Учитывать constraints (min trades, max DD)
- Возвращать оптимальный threshold + метрики
```

### Промпт 3: AutoML и Meta-Learning
```
Реализуй:
1. automl.py - AutoMLPipeline
2. meta_learning.py - MetaLearning для warm-start

AutoML должен:
- Попробовать несколько типов моделей
- Feature selection
- Hyperparameter tuning
- Построить ensemble из лучших

MetaLearning:
- База данных прошлых экспериментов
- Similarity search по meta-features
- Предложение стартовых гиперпараметров
```

### Промпт 4: Experiment tracking и CLI
```
1. src/orchestration/experiment_tracker.py - ExperimentTracker
2. src/interfaces/cli/hyperopt_commands.py - CLI команды

CLI команды:
- hyperopt - запустить поиск гиперпараметров
- automl - запустить AutoML
- compare-experiments - сравнить эксперименты
- best-model - показать лучшую модель

Интеграция с MLflow для storage.
```

## Важные замечания

**Вычислительные ресурсы:**
- Параллельные trials где возможно
- Раннее прерывание (pruning) неперспективных
- Time budget для ограничения времени

**Overfitting:**
- Использовать validation set для optimization
- Резервный test set для финальной оценки
- Cross-validation для надёжности

**Search space:**
- Логарифмическая шкала для learning rate
- Разумные границы для параметров
- Categorical для дискретных выборов

**Reproducibility:**
- Фиксация seeds
- Логирование всех конфигов
- Версионирование кода

## Следующий этап
[Этап 10: Оценка моделей](Этап_10_Оценка_моделей.md)
