# Этап 17: Система мониторинга и логирования

## Цель
Реализовать comprehensive мониторинг, логирование и alerting.

## Зависимости
Этапы 00-16

## Компоненты

### Логирование (docs/system/Logging.md)
```
src/common/logging/
├── __init__.py
├── logger.py                     # Structured logger
├── formatters.py                 # JSON, text formatters
├── handlers.py                   # File, console, MLflow handlers
├── context.py                    # Logging context
└── masking.py                    # PII masking
```

### Мониторинг (docs/system/Monitoring_and_Alerting.md)
```
src/monitoring/
├── metrics_collector.py          # Сбор метрик
├── health_checks.py              # Health checks
├── alerts.py                     # Alerting rules
├── dashboards/                   # Grafana dashboards
└── exporters/                    # Prometheus exporters
```

## Ключевые возможности

### 1. Structured Logging
```python
logger.info(
    "Training completed",
    extra={
        'model_type': 'lightgbm',
        'experiment_id': 'exp_001',
        'duration_sec': 125.5,
        'final_loss': 0.234,
        'gpu_used': True
    }
)
```

**Форматы:**
- JSON для machine parsing
- Human-readable для console
- MLflow для experiment tracking

### 2. Log Levels
- DEBUG: Детальная диагностика
- INFO: Ключевые события
- WARNING: Предупреждения
- ERROR: Ошибки (recoverable)
- CRITICAL: Критичные ошибки

### 3. Rotation
- По размеру (50MB)
- По времени (daily)
- Compression старых логов
- Retention policy (30 дней)

### 4. Metrics Collection
```python
class MetricsCollector:
    """Сбор метрик для мониторинга"""

    # System metrics
    def collect_cpu_usage(self): ...
    def collect_memory_usage(self): ...
    def collect_gpu_usage(self): ...
    def collect_disk_usage(self): ...

    # Application metrics
    def collect_training_metrics(self): ...
    def collect_backtest_metrics(self): ...
    def collect_api_latency(self): ...
    def collect_error_rate(self): ...
```

### 5. Health Checks
```python
class HealthChecker:
    """Проверки состояния системы"""

    def check_database(self): ...
    def check_mlflow(self): ...
    def check_disk_space(self): ...
    def check_gpu_availability(self): ...

    def overall_health(self) -> HealthStatus:
        """Aggregated health status"""
```

### 6. Alerting
```yaml
# configs/monitoring/alerts.yaml
alerts:
  - name: high_error_rate
    condition: error_rate > 0.1
    severity: critical
    channels: [email, slack]

  - name: low_disk_space
    condition: disk_free_pct < 10
    severity: warning
    channels: [slack]

  - name: training_failed
    condition: training_status == 'failed'
    severity: error
    channels: [email]

  - name: gpu_utilization_low
    condition: gpu_usage < 0.3
    severity: info
    channels: [slack]
```

### 7. Dashboards

**Grafana dashboards:**
- System resources (CPU, Memory, GPU, Disk)
- Application metrics (training, backtest)
- Error rates
- API latency
- Experiment tracking

## Integration Points

### MLflow
- Training metrics
- Model metrics
- Experiment metadata
- Artifacts

### Prometheus
- System metrics
- Application metrics
- Custom metrics

### Grafana
- Визуализация
- Dashboards
- Alerts

## Конфигурация

**configs/logging/default.yaml:**
```yaml
logging:
  version: 1

  formatters:
    json:
      class: src.common.logging.formatters.JSONFormatter

    detailed:
      format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'

  handlers:
    console:
      class: logging.StreamHandler
      formatter: detailed
      level: INFO

    file:
      class: logging.handlers.RotatingFileHandler
      filename: artifacts/logs/app.log
      maxBytes: 52428800  # 50MB
      backupCount: 10
      formatter: json
      level: DEBUG

    mlflow:
      class: src.common.logging.handlers.MLflowHandler
      level: INFO

  root:
    level: DEBUG
    handlers: [console, file, mlflow]
```

## Критерии готовности

- [ ] Structured logging работает
- [ ] JSON и text formatters
- [ ] Log rotation
- [ ] MLflow integration для логов
- [ ] Metrics collection (system + app)
- [ ] Health checks
- [ ] Alerting система
- [ ] Prometheus exporter
- [ ] Grafana dashboards
- [ ] PII masking

## Промпты

```
Реализуй систему логирования в src/common/logging/:
1. logger.py - Structured logger wrapper
2. formatters.py - JSON и text formatters
3. handlers.py - Custom handlers (MLflow, etc)
4. context.py - Logging context manager
5. masking.py - PII masking (API tokens, emails)

Реализуй мониторинг в src/monitoring/:
1. metrics_collector.py - MetricsCollector
2. health_checks.py - HealthChecker
3. alerts.py - Alerting engine
4. exporters/prometheus.py - Prometheus exporter

Создай Grafana dashboards в src/monitoring/dashboards/

Используй спецификации из:
- docs/system/Logging.md
- docs/system/Monitoring_and_Alerting.md
```

## Важные замечания

**Security:**
- Не логировать секреты (токены, пароли)
- Маскировать PII
- Secure storage для логов

**Performance:**
- Async logging для performance
- Sampling для high-volume logs
- Buffering

**Retention:**
- Старые логи архивировать
- Compliance requirements

## Следующий этап
[Этап 18: Распределённые вычисления](Этап_18_Распределённые_вычисления.md)
