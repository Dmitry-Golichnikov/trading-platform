# Техническое задание: модульная платформа разработки и тестирования торговых моделей

## 1. Цели и охват
- Создать воспроизводимую систему для подготовки данных, обучения моделей и бэктестинга торговых стратегий на локальной машине.
- Обеспечить прозрачность экспериментов, контроль версий данных и конфигураций, удобный UX и минимальный технический долг.
- Сформировать основу, пригодную для дальнейшего перехода к онлайн-торговле через API Тинькофф Инвестиций.

## 2. Пользовательские сценарии
- Загрузка и нормализация исторических данных из локальных файлов и Tinkoff Investments API.
- Конфигурирование пайплайнов подготовки признаков и таргетов, работа с вариативными элементами.
- Обучение моделей (ML/NN) с поиском гиперпараметров и логированием экспериментов.
- Бэктест стратегий, анализ метрик, визуализация результатов.
- Работа через CLI/GUI, параллельное ведение нескольких задач.

## 3. Логическая архитектура
- `src/data/` — ingestion из локальных файлов и Tinkoff API, проверка целостности, нормализация таймзон, каталогизация и версионирование датасетов/артефактов.
- `src/features/` — декларативные пайплайны построения признаков, кэширование многооконных расчётов, валидация конфигураций и библиотека индикаторов.
- `src/labeling/` — генерация таргетов (horizon/triple barrier/кастом), постфильтры, логирование метаданных и версий разметки.
- `src/modeling/` — единый интерфейс моделей, тренинг (GPU/CPU), подбор гиперпараметров, оптимизаторы, трекинг экспериментов и реестр сохранённых моделей.
- `src/evaluation/` — расчёт метрик моделей, калибровка, анализ важности, детект дрейфа и отчёты.
- `src/backtesting/` — движок стратегий, правила входа/выхода, расчёт PnL и риск-метрик, учёт комиссий и проскальзывания.
- `src/pipelines/` — описания end-to-end сценариев (подготовка данных, обучение, walk-forward, бэктест, деплой), контроль идемпотентности и перезапусков.
- `src/orchestration/` — абстракции для CLI-команд, планировщиков, очередей задач и интеграции с MLflow.
- `src/interfaces/cli/` и `src/interfaces/gui/` — пользовательские взаимодействия: конфигурирование, мониторинг прогресса, визуализации.
- `src/common/` — общие утилиты, логирование, валидация схем, адаптеры для хранилищ, обёртки над API.
- `configs/` — версионированные YAML/JSON (пайплайны, признаки, таргеты, модели, бэктесты, окружения).
- `docs/` — техническая документация, гайды, идеи, отчёты, roadmap.
- `artifacts/` — структурированное хранение моделей, датасетов, логов и отчётов с хешами и метаданными.
- `tests/` — модульные, интеграционные и регрессионные сценарии для основных пайплайнов.
- `scripts/` и `infra/` — вспомогательные утилиты, Dockerfile, требования окружения, CI/CD.

## 4. Данные и управление
- Источники:
  - Локальные файлы CSV/Parquet.
  - Tinkoff Investments API (торговые данные, стаканы, статус торгов).
- Требования:
  - Таймзона и частота данных должны быть явно заданы.
  - Проверки целостности: пропуски, дубликаты, консистентность цен/объёмов.
  - Каталогизация наборов данных: метаданные (источник, период, фильтры, версия схемы), единый формат хранения (Parquet), именование колонок (timestamp, open, high, low, close, volume, ticker и т.п.).
  - Версионирование датасетов и артефактов (метки, признаки) с фиксацией хеша сырьевых данных.
- Обязательная выгрузка исторических минутных данных через Tinkoff Investments API по годовым архивам с дальнейшим пересэмплированием в 5m, 15m, 1h, 4h и 1d; результаты складываются в структурированные каталоги `artifacts/data/{ticker}/{timeframe}` для ускорения повторного использования и построения пайплайнов.

## 5. Обработка данных
- Конвейер фильтрации (конфигурируемый): объединение источников, исправление/удаление аномалий, клининг событий (новости, roll-over), работа с ликвидностью.
- Логирование статистики фильтров (кол-во строк, доля выбросов, причина).
- Поддержка идемпотентности: повторный запуск фильтров должен давать одинаковый результат.

## 6. Признаки
- Декларативное описание в конфигурациях (YAML/JSON).
- Поддержка многооконности и агрегаций, кэширование промежуточных расчётов.
- Каталоги заранее рассчитанных признаков, хранящих группы фич с версиями и метаданными, чтобы переиспользовать их в экспериментах и подключать модуль поиска признаков без повторного пересчёта.
- Список индикаторов (все должны работать каузально):
  - SMA, EMA, WMA
  - MACD
  - RSI
  - Stochastic Oscillator, Stochastic RSI
  - Bollinger Bands
  - ATR
  - ADX
  - Ichimoku Cloud
  - Parabolic SAR
  - VWAP
  - OBV
  - Chaikin Money Flow
  - Volume Metrics (Total, Money Volume, Volume Change, Average Volume)
  - Volume Profile, Horizontal Volume
  - CCI
  - Accumulation/Distribution
  - Donchian Channels
  - Keltner Channels
  - Heikin-Ashi
  - Pivot Points (Classic/Fibonacci/Camarilla)
  - Williams %R
  - TRIX
  - Elder Force Index
  - Money Flow Index
  - Detrended Price Oscillator
  - Fractal Dimension Index
  - Nadaraya-Watson Envelope
- Признаки: текущий таймфрейм, старшие таймфреймы, ценовые/объёмные/календарные/тикерные признаки, внешние сигналы.
- Валидация конфигураций (schema): корректность параметров индикаторов, исключение look-ahead.

## 7. Разметка таргетов
- Поддержка horizon, triple barrier, кастомных правил.
- Режимы: long-only, short-only, long+short, multi-class.
- Параметры:
  - горизонты (фиксированные/адаптивные)
  - верхний/нижний барьер (процентный, ATR, волатильностный)
  - временной барьер
  - симметричные/асимметричные барьеры
  - фильтры по волатильности, событиям, индикаторным сигналам
- Постфильтры: сглаживание, минимальная длина последовательностей, majority vote, отсечение опасных зон, логирование изменений.
- Метаданные: версия разметки, список фильтров, источники данных.

## 8. Модели и обучение
- Единый интерфейс моделей: `fit`, `predict`, `predict_proba`, `save`, `load`.
- Поддерживаемые классы моделей:
  - Линейные (логистическая регрессия, ElasticNet)
  - Ансамбли (LightGBM, CatBoost, XGBoost, RandomForest, ExtraTrees)
  - Нейросети для табличных данных (TabNet, FT-Transformer, NODE)
  - Последовательные (LSTM, GRU, Seq2Seq, TCN, Temporal Fusion Transformer, Informer, 1D-CNN+LSTM)
- Обучение на GPU (PyTorch), возможность отключения GPU через конфиг.
- Список функций потерь: BCE, Weighted/Cost-sensitive, Focal, Label Smoothing, MSE/MAE/Huber, Quantile, Ranking, SoftF1, Tversky, кастомные трейдинговые функции.
- Гиперпараметры: learning rate/schedulers, параметры деревьев, регуляризация, параметры последовательных моделей, batching/optimization, data augmentation, мета-параметры (early stopping, seeds).
- Оптимизаторы: SGD, Adam/AdamW/AMSGrad/Nadam, Ranger/RAdam/AdaBelief/Lion, Shampoo/Adafactor, LAMB/LARS, LR schedulers (Cosine, OneCycle, Cyclical, ReduceLROnPlateau, Hyperband/BOHB), gradient clipping, EMA, SAM.
- Система трекинга экспериментов (MLflow или аналог): метрики, артефакты, конфиги, код.
- Поддержка моделей в режимах классификации и регрессии в рамках единого интерфейса, включая возможность переключения loss-функций и метрик через конфигурации.
- Механизм нормировки таргета с учётом профиля сделки (тейк-профит, стоп-лосс, комиссии) для приоритизации сигналов по соотношению прибыль/риск.
- Автоматические sanity-checks перед запуском обучения: проверка распределения таргетов, look-ahead, доли пропусков и других потенциальных утечек.
- Meta-learning слой: сохранение портретов моделей (важность признаков, лучшие гиперпараметры, устойчивость) и использование warm-start при новых поисках.
- Контейнерные профили для CPU/GPU (`docker-compose.cpu.yml`, `docker-compose.gpu.yml`), обеспечивающие воспроизводимость среды и быстрый переключатель между режимами исполнения.

## 9. Вариативные элементы и поиск
- Обучение: тикеры, таймфреймы, направление торговли, параметры horizon/triple barrier, фильтры данных, признаки, архитектуры моделей, функции потерь, оптимизаторы, гиперпараметры.
- Тестирование стратегий: пороги входа/выхода, тейк-профит, стоп-лосс, трейлинг-стоп, длительность удержания.
- Единый механизм поиска (grid/random/Bayesian/адаптивные алгоритмы, генетические алгоритмы) с ограничением бюджета, логированием результатов, возможностью перезапуска.
- Автопоиск лучших конфигураций с режимом «заморозки» блоков (разметка данных, признаки, модели, гиперпараметры обучения и моделей, параметры стратегии) для изолированной оптимизации.
- Многоуровневая последовательность оптимизации: стабилизация данных, грубый поиск гиперпараметров, оптимизация признаков, тонкая настройка моделей, выбор режима (классификация/регрессия), подбор торговых параметров, финальная валидация устойчивости.
- Компонент оптимизации порога по ожидаемому PnL с использованием формулы `E[PnL] = p_up * TP - (1 - p_up) * SL - комиссии` и поддержкой ограничений (минимум сделок, штраф за риск).

## 10. Бэктест и оценка стратегий
- Метрики моделей: Accuracy, Precision/Recall/F1, ROC-AUC, PR-AUC, MCC, calibration, PSI, drift detection.
- Метрики стратегий: Sharpe, Sortino, Calmar, Max Drawdown, Hit Rate, Profit Factor, Payoff Ratio, Average Trade Return, Time in Market, VaR, CVaR, Tail Ratio, Turnover, Slippage-adjusted PnL, комиссии.
- Выделение стратегий, показывающих положительный результат (PnL > 0) на тренировочном, валидационном и тестовом наборах, с визуализацией в отчётах и GUI.
- Варианты выходов из сделки:
  - Тейк-профит (процентный, ATR/волатильностный)
  - Стоп-лосс (процентный, ATR/волатильностный)
  - Трейлинг-стоп (по цене, ATR, индикатору)
  - Временной стоп
  - Обратный сигнал модели/индикатора
  - Частичное закрытие (scale-out)
  - Риск-параметры (максимальный дневной/портфельный убыток)
- При совпадении условий стоп-лосса и тейк-профита на одном баре приоритет у стоп-лосса.
- При достижении стоп-лосса и прочего, сделка закрывается сразу, а не ждет следующего бара.
- Учет комиссий/проскальзывания как параметров стратегий.

## 11. Пайплайны
- Подготовка данных: загрузка, проверка, синхронизация таймзон, базовые фильтры.
- Генерация признаков: технические, объёмные, межтаймфреймовые, внешние источники.
- Нормализация: z-score, min-max, robust процедуры, обработка выбросов.
- Отбор признаков: filter/wrapper/embedded, PCA/UMAP/autoencoder, drift-селекторы.
- Разметка и постобогащение: конфигурации таргетов, балансировка классов.
- Обучение: поиск гиперпараметров, обучение итоговых моделей, логирование.
- Валидация: walk-forward/expanding window, расчёт метрик, калибровка, важность признаков.
- Бэктест: расчёт торговых метрик, отчёты, визуализации.
- Деплой/мониторинг (после офлайн-этапа): экспорт моделей, настройка production pipeline, мониторинг дрейфа.
- Ранняя остановка неэффективных конфигураций во время обучения и бэктестов для экономии вычислительных ресурсов.
- Оркестрация оптимизации в виде сценариев с чекпоинтами, фиксирующих лучшие результаты на каждом этапе.

## 12. Артефакты и хранение
- Модели и веса: PyTorch (`.pt/.pth`), ONNX, sklearn pickles, CatBoost/LightGBM/XGBoost бинарники.
- Конфигурации: YAML/JSON (разметка, признаки, гиперпараметры, фильтры).
- Метрики и логи: MLflow metrics, JSON/CSV отчёты, TensorBoard events.
- Отчёты/визуализации: HTML/PDF, PNG/SVG, auto-generated notebooks.
- Датасеты: Parquet, Feather, Delta, хранилища (локально, MinIO/S3, feature store).
- Бэктесты: Parquet/CSV/JSON, метаданные (комиссии, параметры стратегии).
- Скрипты и окружения: `requirements.txt`, Dockerfile, Conda env, hash зависимостей.
- Политика версионирования: фиксация версий/хешей, хранение в MLflow и репозитории.
- Централизованный реестр конфигураций и метаданных (`artifacts/manifests/*.json`) для идемпотентных операций и повторного использования артефактов.

## 13. Инфраструктура
- Целевая платформа — локальная машина с integrated GPU (с возможностью отключения).
- PyTorch — основной фреймворк для нейросетей.
- Контейнеризация: Docker для воспроизводимости.
- CI/CD-конвейер (GitHub Actions или аналог) с обязательными проверками перед слиянием:
  - статический анализ, форматирование и линтеры для Python/JS, проверка схем и конфигураций (`configs/`).
  - модульные, интеграционные и регрессионные тесты, выборочные бэктесты на эталонных наборах.
  - сборка Docker-образов и публикация артефактов (модели, датасеты, пакеты), проверка воспроизводимости окружения.
  - генерация и публикация документации (`docs/`, `project_learning/*`), выгрузка отчётов и метрик в MLflow.
  - ночные/по расписанию прогоны для мониторинга дрейфа зависимостей и совместимости окружений.
- Управление версиями кода: Git с центральным репозиторием на GitHub, защита ветки `main`, review через pull request.
- Автоматическая синхронизация рабочих устройств: служба на стационарном ПК, отслеживающая обновления в GitHub и выполняющая `git pull` при появлении новых коммитов в основной ветке.
- Распределённые вычисления: оркестратор по умолчанию исполняет обучение, подбор гиперпараметров и бэктесты на стационарном ПК с GPU/расширенными ресурсами, синхронизируя артефакты и логи в центральное хранилище; при недоступности ПК задачи автоматически выполняются локально на ноутбуке.
- Гибкий GUI: пользователь может работать из ноутбука (результаты доставляются обратно в ноутбук) или запустить GUI напрямую на стационарном ПК, когда вычисления и визуализации остаются локальными на нём.
- Безопасность: базовая (ключи API вне репозитория, `.env`), расширенная защита не требуется.
- Оркестрация: CLI/скрипты, idempotent-операции, возможность ручного перезапуска этапов.
- Централизованный monitoring hook для отправки ключевых метрик и предупреждений в MLflow/Grafana/Streamlit.
- Репликация артефактов на внешние хранилища (S3/MinIO) с версионированием и fallback.

## 14. GUI
- Веб/desktop по выбору, приоритет — интуитивность и производительность.
- Основные функции:
  - Управление пайплайнами (запуск, мониторинг прогресса).
  - Настройка конфигураций и вариативных элементов через формы.
  - Просмотр метрик, графиков (эквити-кривые, распределения, важность признаков, диагностика таргетов).
  - Просмотр цены с выбранным индикатором, переключение тикеров/таймфреймов, работа с большими списками (виртуализация).
  - Сохранение/загрузка пресетов настроек.
- Аутентификация не требуется (однопользовательский режим), но предусмотреть логирование действий.
- Расширяемость: поддержка плагинов/виджетов для новых модулей или визуализаций.
- Вкладка сравнения экспериментов с интеграцией MLflow API, таблицами метрик и диаграммами.
- Интерактивный logbook, который автоматически наполняется результатами экспериментов и служит единым источником знаний.

## 15. График внедрения
1. Аудит текущего решения, сбор требований.
2. Проектирование архитектуры (конвейеры, API, конфигурации, хранение артефактов).
3. Реализация конвейеров данных, фильтров, разметки, конфигурационной системы.
4. Реализация и документация вычислительных пайплайнов (feature engineering, обучение, бэктест).
5. Интеграция с Tinkoff API, подготовка к онлайн-режиму (после стабилизации офлайна).
6. Разработка GUI, финальные улучшения UX.
7. Документация (гайды, FAQ, roadmap).

## 16. Критерии готовности
- Все ключевые пайплайны автоматизированы и покрыты тестами.
- Пайплайн подготовки данных и обучения воспроизводим «из коробки».
- Документация актуальна и описывает end-to-end сценарий.
- Бэктест демонстрирует качество не ниже базовой линии.
- Система готова к последующей интеграции с API для реального трейдинга.

## 17. Прочее
- Сплиты по умолчанию: train 70%, val 15%, test 15% (настраиваемые).
- Балансировка классов: коэффициенты/веса, oversampling/undersampling, sequence-aware weighting.
- Рабочие окна: подготовка данных, обучение и бэктест запускаются независимо.
- GPU используется для обучения и тестирования стратегий; возможность падать на CPU при отсутствии GPU, если в настоящий момент на gpu проводится обучение, то тестирование запускается на CPU.
- Комиссии и проскальзывание задаются параметрами бэктестера.
- Дополнительные идеи (например, весовая схема по длине последовательности) фиксируются в `docs/ideas.md` для дальнейших экспериментов.
- Центральный хук мониторинга для отправки метрик/алертов, explainability пак (SHAP, permutation importance), стресс-тестирование синтетическими сценариями.
- План по разработке плагинов для интеграции альтернативных брокерских API с единым интерфейсом.
