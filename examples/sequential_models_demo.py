"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è sequential –º–æ–¥–µ–ª–µ–π.

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LSTM, GRU, TCN, CNN+LSTM –∏ –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏
–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.
"""

import numpy as np
import pandas as pd
import torch

from src.modeling.models.neural.sequential import (
    CNNLSTMModel,
    GRUModel,
    LSTMModel,
    TCNModel,
    get_default_augmentation,
)
from src.modeling.models.neural.sequential.visualization import (
    plot_training_history,
)


def generate_synthetic_data(n_samples: int = 1000, n_features: int = 10):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞.

    Returns:
        X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        y: Series —Å —Ç–∞—Ä–≥–µ—Ç–æ–º
    """
    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é
    t = np.arange(n_samples)

    # –ë–∞–∑–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª
    trend = 0.001 * t
    seasonality = 0.5 * np.sin(2 * np.pi * t / 100)
    noise = 0.1 * np.random.randn(n_samples)

    base_signal = trend + seasonality + noise

    # –°–æ–∑–¥–∞—ë–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    features = {}
    for i in range(n_features):
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏
        lag = np.random.randint(1, 10)
        features[f"feature_{i}"] = np.roll(base_signal, lag) + 0.1 * np.random.randn(n_samples)

    X = pd.DataFrame(features)

    # –¢–∞—Ä–≥–µ—Ç: –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–±—É–¥–µ—Ç –ª–∏ —Ä–æ—Å—Ç)
    y = pd.Series((base_signal > np.roll(base_signal, 1)).astype(int))

    # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –∏–∑-–∑–∞ –ª–∞–≥–æ–≤
    X = X.iloc[10:]
    y = y.iloc[10:]

    return X.reset_index(drop=True), y.reset_index(drop=True)


def demo_lstm():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è LSTM –º–æ–¥–µ–ª–∏."""
    print("=" * 60)
    print("DEMO: LSTM Model")
    print("=" * 60)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    X, y = generate_synthetic_data(n_samples=1000, n_features=10)

    # Split
    train_size = int(0.7 * len(X))
    val_size = int(0.15 * len(X))

    X_train = X.iloc[:train_size]
    y_train = y.iloc[:train_size]
    X_val = X.iloc[train_size : train_size + val_size]
    y_val = y.iloc[train_size : train_size + val_size]
    X_test = X.iloc[train_size + val_size :]
    y_test = y.iloc[train_size + val_size :]

    print(f"Train size: {len(X_train)}")
    print(f"Val size: {len(X_val)}")
    print(f"Test size: {len(X_test)}")

    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å
    model = LSTMModel(
        input_size=X.shape[1],
        hidden_size=64,
        num_layers=2,
        seq_length=30,
        output_size=1,
        dropout=0.2,
        task="classification",
        epochs=20,  # –ú–∞–ª–æ –¥–ª—è –¥–µ–º–æ
        batch_size=32,
        learning_rate=0.001,
        early_stopping=5,
    )

    print(f"\nModel info: {model.get_model_info()}")

    # –û–±—É—á–∞–µ–º
    print("\n–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model.fit(X_train, y_train, X_val, y_val)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print("\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    predictions = model.predict(X_test)
    probabilities = model.predict_proba(X_test)

    # –ú–µ—Ç—Ä–∏–∫–∏
    from sklearn.metrics import accuracy_score, roc_auc_score

    accuracy = accuracy_score(y_test, predictions)
    auc = roc_auc_score(y_test, probabilities[:, 1])

    print(f"\nTest Accuracy: {accuracy:.4f}")
    print(f"Test AUC: {auc:.4f}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    history = model.get_training_history()
    plot_training_history(history, save_path="artifacts/lstm_training.png")
    print("\n–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ artifacts/")


def demo_gru():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è GRU –º–æ–¥–µ–ª–∏."""
    print("\n" + "=" * 60)
    print("DEMO: GRU Model")
    print("=" * 60)

    X, y = generate_synthetic_data(n_samples=1000, n_features=10)

    train_size = int(0.7 * len(X))
    X_train = X.iloc[:train_size]
    y_train = y.iloc[:train_size]
    X_test = X.iloc[train_size:]
    y_test = y.iloc[train_size:]

    model = GRUModel(
        input_size=X.shape[1],
        hidden_size=64,
        num_layers=2,
        seq_length=30,
        epochs=10,
        task="classification",
    )

    print("–û–±—É—á–µ–Ω–∏–µ GRU...")
    model.fit(X_train, y_train)

    predictions = model.predict(X_test)
    accuracy = (predictions == y_test.values[model.seq_length :]).mean()
    print(f"Test Accuracy: {accuracy:.4f}")


def demo_tcn():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è TCN –º–æ–¥–µ–ª–∏."""
    print("\n" + "=" * 60)
    print("DEMO: TCN Model")
    print("=" * 60)

    X, y = generate_synthetic_data(n_samples=1000, n_features=10)

    train_size = int(0.7 * len(X))
    X_train = X.iloc[:train_size]
    y_train = y.iloc[:train_size]
    X_test = X.iloc[train_size:]
    y_test = y.iloc[train_size:]

    model = TCNModel(
        input_size=X.shape[1],
        hidden_size=64,
        num_layers=3,
        seq_length=30,
        kernel_size=3,
        epochs=10,
        task="classification",
    )

    print(f"TCN Receptive Field: {model.get_receptive_field()}")

    print("–û–±—É—á–µ–Ω–∏–µ TCN...")
    model.fit(X_train, y_train)

    predictions = model.predict(X_test)
    accuracy = (predictions == y_test.values[model.seq_length :]).mean()
    print(f"Test Accuracy: {accuracy:.4f}")


def demo_cnn_lstm():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è CNN+LSTM –º–æ–¥–µ–ª–∏."""
    print("\n" + "=" * 60)
    print("DEMO: CNN+LSTM Model")
    print("=" * 60)

    X, y = generate_synthetic_data(n_samples=1000, n_features=10)

    train_size = int(0.7 * len(X))
    X_train = X.iloc[:train_size]
    y_train = y.iloc[:train_size]
    X_test = X.iloc[train_size:]
    y_test = y.iloc[train_size:]

    model = CNNLSTMModel(
        input_size=X.shape[1],
        hidden_size=64,
        num_layers=2,
        seq_length=30,
        cnn_channels=[16, 32, 64],
        kernel_size=3,
        epochs=10,
        task="classification",
    )

    print("–û–±—É—á–µ–Ω–∏–µ CNN+LSTM...")
    model.fit(X_train, y_train)

    predictions = model.predict(X_test)
    accuracy = (predictions == y_test.values[model.seq_length :]).mean()
    print(f"Test Accuracy: {accuracy:.4f}")


def demo_augmentation():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è data augmentation."""
    print("\n" + "=" * 60)
    print("DEMO: Data Augmentation")
    print("=" * 60)

    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    X = torch.randn(16, 30, 10)  # (batch, seq_len, features)

    # –ü–æ–ª—É—á–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é
    aug = get_default_augmentation(mode="medium")

    # –ü—Ä–∏–º–µ–Ω—è–µ–º
    X_aug = aug(X)

    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É
    diff = torch.abs(X - X_aug).mean()

    print(f"Original shape: {X.shape}")
    print(f"Augmented shape: {X_aug.shape}")
    print(f"Mean difference: {diff:.4f}")
    print("–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")


def demo_comparison():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π."""
    print("\n" + "=" * 60)
    print("DEMO: Model Comparison")
    print("=" * 60)

    X, y = generate_synthetic_data(n_samples=1000, n_features=10)

    train_size = int(0.7 * len(X))
    X_train = X.iloc[:train_size]
    y_train = y.iloc[:train_size]
    X_test = X.iloc[train_size:]
    y_test = y.iloc[train_size:]

    models = {
        "LSTM": LSTMModel(
            input_size=X.shape[1],
            hidden_size=32,
            num_layers=1,
            seq_length=20,
            epochs=5,
        ),
        "GRU": GRUModel(
            input_size=X.shape[1],
            hidden_size=32,
            num_layers=1,
            seq_length=20,
            epochs=5,
        ),
        "TCN": TCNModel(
            input_size=X.shape[1],
            hidden_size=32,
            num_layers=2,
            seq_length=20,
            epochs=5,
        ),
    }

    results = {}

    for name, model in models.items():
        print(f"\n–û–±—É—á–µ–Ω–∏–µ {name}...")
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        accuracy = (predictions == y_test.values[model.seq_length :]).mean()
        results[name] = accuracy
        print(f"{name} Test Accuracy: {accuracy:.4f}")

    # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
    best_model = max(results, key=results.get)
    print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model} ({results[best_model]:.4f})")


if __name__ == "__main__":
    print("Sequential Models Demo\n")
    print("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å sequential –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
    print(f"\nCUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA device: {torch.cuda.get_device_name(0)}")

    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ
    try:
        demo_lstm()
        demo_gru()
        demo_tcn()
        demo_cnn_lstm()
        demo_augmentation()
        demo_comparison()

        print("\n" + "=" * 60)
        print("–í—Å–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω—ã! ‚úÖ")
        print("=" * 60)

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
